{
    "llama-7b":{
        "num_layers": 32,
        "num_heads": 32,
        "hidden_size": 4096,
        "intermediate_size": 11008,
        "vocab_size": 32000,
        "max_seq_len": 2048,
        "model_type": "llama",
        "model_name": "llama-7b"
    },
    "llama-13b":{
        "num_layers": 40,
        "num_heads": 40,
        "hidden_size": 5120,
        "intermediate_size": 13824,
        "vocab_size": 32000,
        "max_seq_len": 2048,
        "model_type": "llama",
        "model_name": "llama-13b"
    },
    "llama-30b":{
        "num_layers": 60,
        "num_heads": 52,
        "hidden_size": 6656,
        "intermediate_size": 17920,
        "vocab_size": 32000,
        "max_seq_len": 2048,
        "model_type": "llama",
        "model_name": "llama-30b"
    },
    "llama-65b":{
        "num_layers": 80,
        "num_heads": 64,
        "hidden_size": 8192,
        "intermediate_size": 22016,
        "vocab_size": 32000,
        "max_seq_len": 2048,
        "model_type": "llama",
        "model_name": "llama-65b"
    },
    "llama2-13b":{
        "num_layers": 40,
        "num_heads": 40,
        "num_kv_heads": 40,
        "hidden_size": 5120,
        "intermediate_size": 13824,
        "vocab_size": 32000,
        "max_seq_len": 4096,
        "model_type": "llama",
        "model_name": "llama2-13b"
    },
    "llama2-70b":{
        "num_layers": 80,
        "num_heads": 64,
        "num_kv_heads": 8,
        "hidden_size": 8192,
        "intermediate_size": 28672,
        "vocab_size": 32000,
        "max_seq_len": 4096,
        "model_type": "llama2",
        "model_name": "llama2-70b"
    },
    "internlm-20b": {
        "num_layers": 60,
        "num_heads": 40,
        "num_kv_heads": 40,
        "hidden_size": 5120,
        "intermediate_size": 13824,
        "vocab_size": 103168,
        "max_seq_len": 16384,
        "model_type": "internlm",
        "model_name": "internlm-20b"
    },
    "internlm2-20b-chat": {
        "num_layers": 48,
        "num_heads": 48,
        "num_kv_heads": 8,
        "hidden_size": 6144,
        "intermediate_size": 16384,
        "vocab_size": 92544,
        "max_seq_len": 32768,
        "model_type": "internlm2",
        "model_name": "internlm2-20b-chat"
    },
    "Qwen3-8B": {
        "num_layers": 36,
        "num_heads": 32,
        "num_kv_heads": 8,
        "hidden_size": 4096,
        "intermediate_size": 12288,
        "vocab_size": 151936,
        "max_seq_len": 40960,
        "model_type": "qwen3",
        "model_name": "Qwen3-8B"
    },
    "Qwen3-32B": {
        "num_layers": 64,
        "num_heads": 64,
        "num_kv_heads": 8,
        "hidden_size": 5120,
        "intermediate_size": 25600,
        "vocab_size": 151936,
        "max_seq_len": 40960,
        "model_type": "qwen3",
        "model_name": "Qwen3-32B"
    }
}
